{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convince Me AutoArena Works\n",
    "\n",
    "Evaluating AI has never been trivial. As traditional ML models evolve into LLMs and datasets take on more complex forms, benchmarking models becomes difficult. **[AutoArena by Kolena](https://github.com/kolenaIO/autoarena)** is a platform made for creating leaderboards to rank LLMs comparing model responses against one another using automated judges.\n",
    "\n",
    "### AutoArena Overview\n",
    "\n",
    "AutoArena sets up head-to-head comparisons of model generations before a jury of LLMs. With multiple automated judges within the jury from different LLM families, the aim is to apply the most ideal measurement of generation quality to critique other model generations. In comparison, traditional text similarity metrics are less relevant in measuring \"quality\". Winners of these head-to-head comparisons gain \"Elo\" - a score that determines a model's overall placement on a leaderboard.\n",
    "\n",
    "### Experiment\n",
    "\n",
    "The necessary dependancies to run this notebook can be installed with: `pip install ipykernel pandas nbformat plotly`.\n",
    "\n",
    "In this notebook, we will use a portion of the data from the [LMSYS - Chatbot Arena Human Preference Predictions](https://www.kaggle.com/competitions/lmsys-chatbot-arena/data) training split, having the [Attribution-NonCommercial 4.0](https://creativecommons.org/licenses/by-nc/4.0/) license. This dataset includes human votes indicating which model's response to a prompt was the best in a pairwise fashion, and the needed data for this experiment has been reformatted in the `models` folder.\n",
    "\n",
    "### Steps in this notebook\n",
    "\n",
    "<style>\n",
    "    .spaced-list li {margin-bottom: 10px;}\n",
    "</style>\n",
    "\n",
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <img src=\"../assets/getting_started.jpg\" width=\"300\"/>\n",
    "    <ol class=\"spaced-list\">\n",
    "        <li>Create a project</li>\n",
    "        <li>Create an automated judge</li>\n",
    "        <li>Upload model responses</li>\n",
    "        <li>Make some hypotheses about LLM rankings</li>\n",
    "        <li>Run the human votes through an <a href=\"https://en.wikipedia.org/wiki/Elo_rating_system\">Elo rating system</a> and check the hypotheses</li>\n",
    "        <li>Verify AutoArena's leaderboard</li>\n",
    "    </ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipykernel pandas nbformat plotly -U -q\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a project\n",
    "\n",
    "To start, install AutoArena from [PyPI](https://pypi.org/project/autoarena/), add your OpenAI API key to your environment for an automated judge, and run it as a module.\n",
    "```bash\n",
    "pip install autoarena\n",
    "export OPENAI_API_KEY=sk-...\n",
    "python -m autoarena\n",
    "```\n",
    "Once the module is running, visit [http://localhost:8899](http://localhost:8899) to create a project! \n",
    "\n",
    "### 2. Create an automated judge\n",
    "\n",
    "Click on `Configure Judge` > `OpenAI` > `gpt-4o-mini` > `Create` which creates a `gpt-4o-mini` judge using your `OPENAI_API_KEY` environment variable.\n",
    "\n",
    "### 3. Upload model responses\n",
    "\n",
    "Let's return to the Leaderboard page to upload our data. The `models` folder contains six CSVs:\n",
    "1. `models/gpt-3.5-turbo-0613.csv`\n",
    "2. `models/gpt-4-0314.csv`\n",
    "3. `models/gpt-4-1106-preview.csv`\n",
    "4. `models/vicuna-13b.csv`\n",
    "5. `models/vicuna-33b.csv`\n",
    "\n",
    "Each CSV contains a `prompt` and `response` column storing a language model's input and output, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General interaction behaviors instructions:\\n\\...</td>\n",
       "      <td>[BEGINIMDETECT]\\n{\\n  \"response\": [\\n    {\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you are a powerhouse of creative brilliance an...</td>\n",
       "      <td>Topic: Sustainable living and eco-friendly pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can you summarize the below \"1\\t0\\tARRISGro_f7...</td>\n",
       "      <td>The text provided is a list of wireless networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apprentissage automatique (Machine Learning) s...</td>\n",
       "      <td>import pandas as pd\\n\\nurl = \"https://wagon-pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you provide a list of 10 youtube video tit...</td>\n",
       "      <td>&lt;answer&gt;\\n&lt;item&gt;Tesla's $300 Wireless Charging...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  General interaction behaviors instructions:\\n\\...   \n",
       "1  you are a powerhouse of creative brilliance an...   \n",
       "2  can you summarize the below \"1\\t0\\tARRISGro_f7...   \n",
       "3  Apprentissage automatique (Machine Learning) s...   \n",
       "4  Can you provide a list of 10 youtube video tit...   \n",
       "\n",
       "                                            response  \n",
       "0  [BEGINIMDETECT]\\n{\\n  \"response\": [\\n    {\\n  ...  \n",
       "1  Topic: Sustainable living and eco-friendly pra...  \n",
       "2  The text provided is a list of wireless networ...  \n",
       "3  import pandas as pd\\n\\nurl = \"https://wagon-pu...  \n",
       "4  <answer>\\n<item>Tesla's $300 Wireless Charging...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(\"models/gpt-4-0314.csv\", usecols=['prompt', 'response'])\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on `Add Model` and select all of them to upload to your project.\n",
    "\n",
    "\n",
    "### 4. Make some hypotheses about LLM rankings\n",
    "\n",
    "Which LLMs align the most with a human voter's preferences?\n",
    "\n",
    "Note that our pool of models are: `gpt-3.5-turbo-0613`, `gpt-4-0314`, `gpt-4-1106-preview`, `vicuna-13b`, and `vicuna-33b`.\n",
    "\n",
    "- **Hypothesis 1: Bigger Models Are Better**\n",
    "   * `gpt-4-*` should outperform `gpt-3.5-turbo-0613`\n",
    "   * `vicuna-33b` should outperform `vicuna-13b`\n",
    "\n",
    "- **Hypothesis 2: Models Made by Major Industry Leaders Are Better**\n",
    "   * Vicuna's models should be closer to the bottom of the leaderboard\n",
    "\n",
    "- **Hypothesis 3: Newer Models Are Better**\n",
    "   * `gpt-4-1106-preview` should outperform all the other models since it is the newest in the group\n",
    "\n",
    "Let's examine what the human votes from the dataset indicate based on win rates over other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=0<br>model_a=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "vicuna-33b",
          "vicuna-13b",
          "gpt-4-0314",
          "gpt-3.5-turbo-0613",
          "gpt-4-1106-preview"
         ],
         "xaxis": "x",
         "y": [
          0.1826923076923077,
          0.21320346320346317,
          0.36616161616161613,
          0.44017094017094016,
          0.5566239316239316
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Approximate Win Rate"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Avg Win Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lmsys-chatbot-arena/train_subset.csv\") # a subset of the original train split\n",
    "\n",
    "def compute_head_to_head_win_rate(battles):\n",
    "    a_win = pd.pivot_table(battles[battles['winner_model_a'] == 1], index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "    b_win = pd.pivot_table(battles[battles['winner_model_b'] == 1], index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "    counts = pd.pivot_table(battles, index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "    return ((a_win + b_win.T) / (counts + counts.T)).mean(axis=1).sort_values(ascending=True)\n",
    "\n",
    "row_beats_col_freq = compute_head_to_head_win_rate(df)\n",
    "fig = px.bar(row_beats_col_freq, title=\"Approximate Win Rate\", text_auto=\".2f\")\n",
    "fig.update_layout(yaxis_title=\"Avg Win Rate\", xaxis_title=\"Model\", showlegend=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we see that within the GPT-family, newer models have higher winning rates. What's interesting is that `vicuna-33b` is worse than `vicuna-13b` by this metric, and we may have expected the opposite. Furthermore, it may be confusing to see `gpt-4-0314` under `gpt-3.5-turbo-0613`. Only some of our hypotheses can agree with the information above.\n",
    "\n",
    "Are win rates a sufficient metric? While they are explainable and easy to compute, win rates lack precision for ties and cannot allow for performance comparisons beyond two models. Think about this senario: a 5-year-old plays chess with a grand master, and the result is that the child wins. Why is the value of this single win equal to the value of winning to a peer of the same skill level?\n",
    "\n",
    "The better solution over win rates is an [Elo rating system](https://en.wikipedia.org/wiki/Elo_rating_system):\n",
    "- Elo adjusts based on opponent's Elo rating; win rate doesnâ€™t\n",
    "- Elo rewards/penalizes draws; win rate ignores draws\n",
    "\n",
    "\n",
    "### 5. Run the human votes through an [Elo rating system](https://en.wikipedia.org/wiki/Elo_rating_system) and check the hypotheses\n",
    "\n",
    "We'll pass along all these head-to-head battles into an Elo rating system. In general, the winner gains some Elo, while the loser's Elo is lowered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Elo rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Elo rating\n",
       "1  gpt-4-1106-preview        1025\n",
       "2          gpt-4-0314        1014\n",
       "3          vicuna-33b         990\n",
       "4  gpt-3.5-turbo-0613         987\n",
       "5          vicuna-13b         984"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lmsys-chatbot-arena/train_subset.csv\", usecols=['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "\n",
    "def compute_elo(battles, K=4, SCALE=400, BASE=10, INIT_RATING=1000):\n",
    "    rating = defaultdict(lambda: INIT_RATING)\n",
    "    for _, model_a, model_b, winner_model_a, winner_model_b, winner_tie in battles.itertuples():\n",
    "        ra, rb = rating[model_a], rating[model_b]\n",
    "        ea, eb = 1 / (1 + BASE ** ((rb - ra) / SCALE)), 1 / (1 + BASE ** ((ra - rb) / SCALE))\n",
    "        sa = 1 if winner_model_a else 0 if winner_model_b else 0.5 if winner_tie else Exception(\"no winner selected\")\n",
    "        rating[model_a] += K * (sa - ea)\n",
    "        rating[model_b] += K * (1 - sa - eb)\n",
    "    return rating\n",
    "\n",
    "def display_leaderboard(ratings):\n",
    "    df = pd.DataFrame(ratings.items(), columns=[\"Model\", \"Elo rating\"]).sort_values(\"Elo rating\", ascending=False).reset_index(drop=True)\n",
    "    df[\"Elo rating\"] = (df[\"Elo rating\"] + 0.5).astype(int)\n",
    "    df.index = df.index + 1\n",
    "    return df\n",
    "\n",
    "elo_ratings = compute_elo(df)\n",
    "display_leaderboard(elo_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the leaderboard above, we see that all the hypotheses' claims are true. The bigger/newer models rank higher than the smaller/older models, and the GPT-family still ranks the highest.\n",
    "\n",
    "With Elo scores, it becomes much easier to interpret if two models are similar in generation quality (e.g. `gpt-3.5-turbo-0613`, `vicuna-13b`, and `vicuna-33b` have very similar standings).\n",
    "\n",
    "### 6. Verify AutoArena's leaderboard\n",
    "\n",
    "By now, your leaderboard on [AutoArena](http://localhost:8899) should have completed the judging process. Let's click on `Recompute Leaderboard` to refresh the leaderboard's content.\n",
    "\n",
    "<img src=\"../assets/recompute.jpg\" width=\"300\"/>\n",
    "\n",
    "\n",
    "You'll find that the leaderboard within [AutoArena](http://localhost:8899) (example below) is very similar to the leaderboard computed above.\n",
    "\n",
    "<img src=\"../assets/leaderboard.jpg\" width=\"800\"/>\n",
    "\n",
    "Again, we see `gpt-4-1106-preview` in first place. All the larger models outperform their smaller counterparts. This time, `vicuna-13b` and `vicuna-33b` no longer have near identical Elo rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook, we evaluated language model responses using **[AutoArena by Kolena](https://github.com/kolenaIO/autoarena)**, the platform designed to rank LLM generations through head-to-head comparisons judged by an automated jury of other LLMs.\n",
    "\n",
    "\n",
    "We used a dataset that included human preferences for pairwise model comparisons, and uploaded data the prompts and responses into AutoArena. Then, the automated judge critiques the raw model responses. To ensure this strategy is sound, we hypothesized which types of LLMs would align most with human preference. We miss the full picture when observing overall winning rates, but gain more understanding by using an Elo rating system. We constructed a leaderboard using the human preferences from the dataset and compared it to the generated leaderboard in Autoarena, and conclude that automated judges produced a strikingly similar ranking, validating our approach.\n",
    "\n",
    "AutoArena can effectively automate model benchmarking with human preference alignment, or any other policies through creating appropriate system prompts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "truth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

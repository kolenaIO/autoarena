{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convince Me AutoArena Works\n",
    "\n",
    "Evaluating AI has never been trivial. As traditional ML models evolve into LLMs and datasets take on more complex forms, benchmarking models becomes difficult. **[AutoArena by Kolena](https://github.com/kolenaIO/autoarena)** is a platform made for creating leaderboards to rank LLM outputs against one another using automated judges.\n",
    "\n",
    "### AutoArena Overview\n",
    "\n",
    "AutoArena sets up head-to-head comparisons of model generations before a jury of LLMs. With multiple automated judges within the jury from different LLM families, the aim is to apply the most ideal measurement of generation quality to critique other model generations. In comparison, traditional text similarity metrics are less relevant to measuring quality. Winners of these head-to-head comparisons gain \"Elo\" - a score that determines a model's overall placement on a leaderboard.\n",
    "\n",
    "### Experiment\n",
    "\n",
    "The necessary dependancies to run this notebook are: `pip install ipykernel pandas nbformat plotly -U`.\n",
    "\n",
    "In this notebook, we will use a portion of the data from the [LMSYS - Chatbot Arena Human Preference Predictions](https://www.kaggle.com/competitions/lmsys-chatbot-arena/data) training split, having the [Attribution-NonCommercial 4.0](https://creativecommons.org/licenses/by-nc/4.0/) license. This dataset includes human votes indicating which model's response to a prompt was the best in a pairwise fashion, and the necessary data is in `/models`.\n",
    "\n",
    "### Steps in this notebook\n",
    "\n",
    "<style>\n",
    "    .spaced-list li {margin-bottom: 10px;}\n",
    "</style>\n",
    "\n",
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <img src=\"../assets/getting_started.png\" width=\"300\"/>\n",
    "    <ol class=\"spaced-list\">\n",
    "        <li>Create a project</li>\n",
    "        <li>Create an automated judge</li>\n",
    "        <li>Upload model responses</li>\n",
    "        <li>Make some hypotheses about LLM rankings</li>\n",
    "        <li>Run the human votes through an <a href=\"https://en.wikipedia.org/wiki/Elo_rating_system\">Elo rating system</a> and check the hypotheses</li>\n",
    "        <li>Verify AutoArena's leaderboard</li>\n",
    "    </ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipykernel pandas nbformat plotly -U -q\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a project\n",
    "\n",
    "To start, install AutoArena from [PyPI](https://pypi.org/project/autoarena/), add your OpenAI API key to your environment for an automated judge, and run it as a module.\n",
    "```bash\n",
    "pip install autoarena\n",
    "export OPENAI_API_KEY=sk-...\n",
    "python -m autoarena\n",
    "```\n",
    "Once the module is running, visit [http://localhost:8899](http://localhost:8899) to create a project! \n",
    "\n",
    "### 2. Create an automated judge\n",
    "\n",
    "Click on `Configure Judge` > `OpenAI` > `gpt-4o-mini` > `Create` which creates a `gpt-4o-mini` judge using your `OPENAI_API_KEY` environment variable.\n",
    "\n",
    "### 3. Upload model responses\n",
    "\n",
    "Let's return to the `Leaderboard` page to upload our data. The `models` folder contains six CSVs:\n",
    "1. `models/gpt-4-0613.csv`\n",
    "2. `models/gpt-4-1106-preview.csv`\n",
    "3. `models/llama-2-7b-chat.csv`\n",
    "4. `models/llama-2-70b-chat.csv`\n",
    "5. `models/vicuna-13b.csv`\n",
    "6. `models/vicuna-33b.csv`\n",
    "\n",
    "Each CSV contains a `prompt` and `response` column storing a language model's input and output, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following article:\\n\\nJohn Pilge...</td>\n",
       "      <td>The article by Oliver Kamm criticizes the work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knowing \"www.hbr.org\\nIn Praise of the\\nIncomp...</td>\n",
       "      <td>The article \"In Praise of the Incomplete Leade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Using belo provide me with different stress te...</td>\n",
       "      <td>cenario as inputs to the FE-QAR model, which t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>System:\\nInstructions:\\nRole: you are an exper...</td>\n",
       "      <td>.type\":null,\"proc.cmdline\":\"node-a\",\"proc.exep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to all known laws of aviation, there...</td>\n",
       "      <td>I can see you're reciting the script of Bee Mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Summarize the following article:\\n\\nJohn Pilge...   \n",
       "1  Knowing \"www.hbr.org\\nIn Praise of the\\nIncomp...   \n",
       "2  Using belo provide me with different stress te...   \n",
       "3  System:\\nInstructions:\\nRole: you are an exper...   \n",
       "4  According to all known laws of aviation, there...   \n",
       "\n",
       "                                            response  \n",
       "0  The article by Oliver Kamm criticizes the work...  \n",
       "1  The article \"In Praise of the Incomplete Leade...  \n",
       "2  cenario as inputs to the FE-QAR model, which t...  \n",
       "3  .type\":null,\"proc.cmdline\":\"node-a\",\"proc.exep...  \n",
       "4  I can see you're reciting the script of Bee Mo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(\"models/gpt-4-0613.csv\", usecols=['prompt', 'response'])\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on `Add Model` and select all of them to upload to your project.\n",
    "\n",
    "\n",
    "### 4. Make some hypotheses about LLM rankings\n",
    "\n",
    "Which LLMs align the most with a human voter's preferences?\n",
    "\n",
    "Note that our pool of models are: `gpt-4-0613`, `gpt-4-1106-preview`, `llama-2-7b-chat`, `llama-2-70b-chat`, `vicuna-13b`, and `vicuna-33b`.\n",
    "\n",
    "- **Hypothesis 1: Bigger Models Are Better**\n",
    "   * `llama-2-70b-chat` should outperform `llama-2-7b-chat`\n",
    "   * `vicuna-33b` should outperform `vicuna-13b`\n",
    "\n",
    "- **Hypothesis 2: Models Made by Major Industry Leaders Are Better**\n",
    "   * Vicuna's models should be closer to the bottom of the leaderboard\n",
    "\n",
    "- **Hypothesis 3: Newer Models Are Better**\n",
    "   * `gpt-4-1106-preview` should outperform all the other models since it is the newest in the group\n",
    "\n",
    "Let's examine what the human votes from the dataset indicate based on win rates over other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=0<br>model_a=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "llama-2-7b-chat",
          "vicuna-13b",
          "llama-2-70b-chat",
          "vicuna-33b",
          "gpt-4-0613",
          "gpt-4-1106-preview"
         ],
         "xaxis": "x",
         "y": [
          0.13666666666666666,
          0.191526781444285,
          0.23719512195121953,
          0.3111477761836442,
          0.5128937007874015,
          0.5471653543307087
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Approximate Win Rate"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Avg Win Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lmsys-chatbot-arena/train_subset.csv\") # a subset of the original train split\n",
    "\n",
    "def compute_head_to_head_win_rate(battles):\n",
    "    a_win = pd.pivot_table(battles[battles['winner_model_a'] == 1], index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "    b_win = pd.pivot_table(battles[battles['winner_model_b'] == 1], index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "    counts = pd.pivot_table(battles, index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "    return ((a_win + b_win.T) / (counts + counts.T)).mean(axis=1).sort_values(ascending=True)\n",
    "\n",
    "row_beats_col_freq = compute_head_to_head_win_rate(df)\n",
    "fig = px.bar(row_beats_col_freq, title=\"Approximate Win Rate\", text_auto=\".2f\")\n",
    "fig.update_layout(yaxis_title=\"Avg Win Rate\", xaxis_title=\"Model\", showlegend=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we do see that the biggest model within each model family is better and that newer models are better. Win rates by model satisfy all of the hypotheses we made, but we may have expected that `llama-2-70b-chat` would be better than `vicuna-33b`.\n",
    "\n",
    "Are win rates a sufficient metric? While they are explainable and easy to compute, win rates lack precision for ties. Think about this senario: a 5 year old plays chess with a grand master, and the result is that the child wins. Why is the value of this +1 win equal to the value of winning to a peer of the same skill level?\n",
    "\n",
    "The better solution over win rates is an [Elo rating system](https://en.wikipedia.org/wiki/Elo_rating_system):\n",
    "- Elo adjusts based on opponent's Elo rating; win rate doesn’t\n",
    "- Elo rewards/penalizes draws; win rate ignores draws\n",
    "\n",
    "\n",
    "### 5. Run the human votes through an [Elo rating system](https://en.wikipedia.org/wiki/Elo_rating_system) and check the hypotheses\n",
    "\n",
    "We'll pass along all these head-to-head battles into an Elo rating system. In general, the winner gains some Elo, while the loser's Elo is lowered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Elo rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Elo rating\n",
       "1  gpt-4-1106-preview        1039\n",
       "2          gpt-4-0613        1023\n",
       "3          vicuna-33b         992\n",
       "4    llama-2-70b-chat         986\n",
       "5     llama-2-7b-chat         981\n",
       "6          vicuna-13b         979"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"lmsys-chatbot-arena/train_subset.csv\", usecols=['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "\n",
    "def compute_elo(battles, K=4, SCALE=400, BASE=10, INIT_RATING=1000):\n",
    "    rating = defaultdict(lambda: INIT_RATING)\n",
    "    for _, model_a, model_b, winner_model_a, winner_model_b, winner_tie in battles.itertuples():\n",
    "        ra, rb = rating[model_a], rating[model_b]\n",
    "        ea, eb = 1 / (1 + BASE ** ((rb - ra) / SCALE)), 1 / (1 + BASE ** ((ra - rb) / SCALE))\n",
    "        sa = 1 if winner_model_a else 0 if winner_model_b else 0.5 if winner_tie else Exception(\"no winner selected\")\n",
    "        rating[model_a] += K * (sa - ea)\n",
    "        rating[model_b] += K * (1 - sa - eb)\n",
    "    return rating\n",
    "\n",
    "def display_leaderboard(ratings):\n",
    "    df = pd.DataFrame(ratings.items(), columns=[\"Model\", \"Elo rating\"]).sort_values(\"Elo rating\", ascending=False).reset_index(drop=True)\n",
    "    df[\"Elo rating\"] = (df[\"Elo rating\"] + 0.5).astype(int)\n",
    "    df.index = df.index + 1\n",
    "    return df\n",
    "\n",
    "elo_ratings = compute_elo(df)\n",
    "display_leaderboard(elo_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the leaderboard above, we see that all the hypotheses' claims are true. With Elo scores, it becomes much easier to interpret if two models are similar in generation quality (e.g. `llama-2-7b-chat` and `vicuna-13b` have very similar levels of performance).\n",
    "\n",
    "### 6. Verify AutoArena's leaderboard\n",
    "\n",
    "By now, your leaderboard on [AutoArena](http://localhost:8899) should have completed the judging process. Let's click on `Recompute Leaderboard` to refresh the leaderboard's content.\n",
    "\n",
    "<img src=\"../assets/recompute.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "You'll find that the leaderboard within [AutoArena](http://localhost:8899) (example below) is very similar to the leaderboard computed above.\n",
    "\n",
    "<img src=\"../assets/elo_scores.png\" width=\"800\"/>\n",
    "\n",
    "Again, we see `gpt-4-1106-preview` at the top of the ranking, and all the larger models outperform their smaller counterparts. This time, `llama-2-7b-chat` and `vicuna-13b` have near identical Elo rating. Perhaps the hypothesis that Vicuna's models are worse is incorrect. Vicuna's models are [fine-tuned on Llama](https://lmsys.org/blog/2023-03-30-vicuna/) afterall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook, we evaluated language model responses using **[AutoArena by Kolena](https://github.com/kolenaIO/autoarena)**, the platform designed to rank LLM generations through head-to-head comparisons judged by an automated jury of other LLMs.\n",
    "\n",
    "\n",
    "We used a dataset that included human preferences in pairwise model comparisons and uploaded its data without the human indicators into AutoArena. Then, we set up a jury of automated judges to critique the raw model responses given their respective prompts. To ensure this strategy is sound, we hypothesized which types of LLMs would align most closely with human voters' preferences from observing overall winning rates. By using an Elo rating system, we ranked models using the human preferences from the dataset and compared it to the generated leaderboard in Autoarena. We compared the Elo leaderboard with our hypothesis and *ground truth* leaderboard to find that the automated judges produced a strikingly similar ranking, validating our approach.\n",
    "\n",
    "AutoArena can effectively automate model benchmarking and align results with human preferences, or any other policies through creating appropriate system prompts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

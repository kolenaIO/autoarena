{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convince Me This Works\n",
    "\n",
    "Evaluating AI has never been trivial. As traditional ML models evolve into LLMs and datasets take on more complex forms, benchmarking models becomes difficult. **[AutoArena by Kolena](https://github.com/kolenaIO/autoarena)** is a platform made for creating leaderboards to rank LLM outputs against one another using automated judges.\n",
    "\n",
    "### AutoArena Overview\n",
    "\n",
    "AutoArena sets up head-to-head comparisons of model generations before a jury of LLMs. With multiple automated judges within the jury from different LLM families, the aim is to apply the most ideal measurement of generation quality to critique other model generations. In comparison, traditional text similarity metrics are less relevant to measuring quality. Winners of these head-to-head comparisons gain \"Elo\" - a score that determines a model's overall placement on a leaderboard.\n",
    "\n",
    "### Experiment\n",
    "\n",
    "In this notebook, we will use the [LMSYS - Chatbot Arena Human Preference Predictions](https://www.kaggle.com/competitions/lmsys-chatbot-arena/data) dataset having the [Attribution-NonCommercial 4.0](https://creativecommons.org/licenses/by-nc/4.0/) license. This dataset includes human votes indicating which model's response to a prompt was the best in a pairwise fashion. To follow along, please download the dataset from [here](https://www.kaggle.com/competitions/lmsys-chatbot-arena/data?select=train.csv).\n",
    "\n",
    "### Steps in this notebook\n",
    "\n",
    "1. Reformat the dataset for [AutoArena](https://github.com/kolenaIO/autoarena/tree/trunk?tab=readme-ov-file#-getting-started)\n",
    "2. Upload the data into AutoArena\n",
    "3. Create a jury of automated judges. While the automated judges run in the background...\n",
    "4. Make a hypothesis. Which LLMs align the most with a human voter's preferences?\n",
    "5. Run the human votes through an [Elo rating system](https://en.wikipedia.org/wiki/Elo_rating_system)\n",
    "6. Verify that the Elo leaderboard agrees with our hypothesis\n",
    "7. Learn that the automated judges in AutoArena produced a very similar leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reformat the dataset for [AutoArena](https://github.com/kolenaIO/autoarena/tree/trunk?tab=readme-ov-file#-getting-started)\n",
    "The `train` split of the `lmsys-chatbot-arena` dataset is structured in a way where two models are given a prompt, and both models provide their answers. There's an indicator for the human voters to decide whether `model_a` won, `model_b` won, or that it was a tie.\n",
    "\n",
    "AutoArena requires that each models' unique prompts with responses to be in its own CSV with the columns `prompt` and `response`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lmsys-chatbot-arena/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create `auto_arena_df`, has all of the prompts and responses, where models are no longer paired together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>model</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt               model  \\\n",
       "0  Is it morally right to try to have a certain p...  gpt-4-1106-preview   \n",
       "1  What is the difference between marriage licens...           koala-13b   \n",
       "2  explain function calling. how would you call a...  gpt-3.5-turbo-0613   \n",
       "3  How can I create a test set for a very rare ca...    llama-2-13b-chat   \n",
       "4  What is the best way to travel from Tel-Aviv t...           koala-13b   \n",
       "\n",
       "                                            response  \n",
       "0  The question of whether it is morally right to...  \n",
       "1  A marriage license is a legal document that al...  \n",
       "2  Function calling is the process of invoking or...  \n",
       "3  Creating a test set for a very rare category c...  \n",
       "4  The best way to travel from Tel Aviv to Jerusa...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_arena_df = pd.concat(\n",
    "    [\n",
    "        df[['prompt', 'model_a', 'response_a']].rename(columns={'model_a': 'model', 'response_a': 'response'}),\n",
    "        df[['prompt', 'model_b', 'response_b']].rename(columns={'model_b': 'model', 'response_b': 'response'})\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "auto_arena_df['prompt'] = auto_arena_df['prompt'].apply(lambda x: json.loads(x)[0])\n",
    "auto_arena_df['response'] = auto_arena_df['response'].apply(lambda x: json.loads(x)[0])\n",
    "auto_arena_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split up the data into one CSV per model, containing the `prompt` and `response` columns. We will consider the top 40 most involved models to keep things simpler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'models'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "model_counts = list(auto_arena_df['model'].value_counts().items())[:40]\n",
    "models_of_interest = []\n",
    "for model_name, count in model_counts:\n",
    "    models_of_interest.append(model_name)\n",
    "    model_level_df = auto_arena_df[auto_arena_df['model'] == model_name]\n",
    "    # Ensure that the prompt column is unique\n",
    "    model_level_df.drop_duplicates(subset='prompt').to_csv(f'{folder}/{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload the data into AutoArena\n",
    "The `models` folder contains 40 CSVs. Let's go to AutoArena and upload them all, and create a `gpt-4o-mini` judge. If you want to add API keys for other LLM providers, details are available within the UI, or you can see what's available from the [source code here](https://github.com/kolenaIO/autoarena/blob/96ea0326404215891051fad3d7b83db49ab77070/ui/src/components/Judges/types.ts#L111C17-L111C38). To start, simply open your terminal, install AutoArena from [PyPI](https://pypi.org/project/autoarena/), add an OpenAI API key to your environment, and run it as a module.\n",
    "```bash\n",
    "pip install autoarena\n",
    "export OPENAI_API_KEY=sk-...\n",
    "python -m autoarena\n",
    "```\n",
    "Once the module is running, visit [http://localhost:8899](http://localhost:8899) to create a project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a jury of automated judges\n",
    "\n",
    "<img src=\"./assets/tutorial.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "Let's follow the steps within the tutorial.\n",
    "\n",
    "1. Create a project with a name of your choice via the UI\n",
    "2. Add responses from a model by selecting a CSV, such as `models/alpaca-13b.csv`\n",
    "3. Configure an automated judge via the UI by selecting OpenAI from the \"Judges\" page, anc choosing `gpt-4o-mini`\n",
    "4. Add responses from another model (select all the remaining ones in `models`) and the `gpt-4o-mini` judge will automatically start voting\n",
    "\n",
    "While we wait for our jury to go through the thousands of comparisons of model responses in AutoArena, let's see what the human ratings from the dataset reveals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make a hypothesis\n",
    "\n",
    "Based on the overall win rates of each LLM from the dataset, we can see which ones align most with human preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=0<br>model_a=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "gpt-4-1106-preview",
          "gpt-4-0125-preview",
          "gpt-4-0613",
          "gpt-4-0314",
          "gpt-3.5-turbo-0314",
          "claude-2.0",
          "claude-1",
          "gpt-3.5-turbo-0613",
          "mistral-medium",
          "claude-instant-1",
          "claude-2.1",
          "vicuna-33b",
          "mixtral-8x7b-instruct-v0.1",
          "gemini-pro",
          "wizardlm-70b",
          "wizardlm-13b",
          "gemini-pro-dev-api",
          "llama-2-70b-chat",
          "llama-2-13b-chat",
          "tulu-2-dpo-70b",
          "starling-lm-7b-alpha",
          "palm-2",
          "yi-34b-chat",
          "openchat-3.5",
          "pplx-70b-online",
          "gpt-3.5-turbo-1106",
          "llama-2-7b-chat",
          "codellama-34b-instruct",
          "vicuna-7b",
          "zephyr-7b-beta",
          "vicuna-13b",
          "pplx-7b-online",
          "koala-13b",
          "mistral-7b-instruct",
          "qwen-14b-chat",
          "alpaca-13b",
          "RWKV-4-Raven-14B",
          "chatglm-6b",
          "oasst-pythia-12b",
          "fastchat-t5-3b"
         ],
         "xaxis": "x",
         "y": [
          0.5662630549700305,
          0.5481283979392881,
          0.5225148172713447,
          0.5118510768083556,
          0.5062429551639266,
          0.4561650953025705,
          0.44900037115189445,
          0.4262521861870205,
          0.41734811480308887,
          0.40629904164305336,
          0.38922788855160695,
          0.3830897988205385,
          0.37228073399248335,
          0.3645164583264671,
          0.3623238671810245,
          0.35975678167773717,
          0.3572969801755076,
          0.34841686580432096,
          0.3331996922989308,
          0.33267916745612014,
          0.3322934219501645,
          0.3312559102591628,
          0.3306812564462819,
          0.3232315539606911,
          0.32085600383637536,
          0.31933703489912635,
          0.3048484601017646,
          0.28568969534427213,
          0.28228476117406937,
          0.2803621421206567,
          0.27890392294984245,
          0.24299574063802604,
          0.2283690510811727,
          0.22185043664270584,
          0.20993395944551235,
          0.19500337999123282,
          0.18624993212045854,
          0.17990534184976953,
          0.15185084790677195,
          0.13828502858695493
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Approximate Win Rate Against Other Models"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Average Win Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_head_to_head_win_rate(battles):\n",
    "    a_win = pd.pivot_table(\n",
    "        battles[battles['winner_model_a'] == 1],\n",
    "        index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "\n",
    "    b_win = pd.pivot_table(\n",
    "        battles[battles['winner_model_b'] == 1],\n",
    "        index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "\n",
    "    num_battles = pd.pivot_table(battles,\n",
    "        index=\"model_a\", columns=\"model_b\", aggfunc=\"size\", fill_value=0)\n",
    "\n",
    "    # Computing the proportion of wins for each model as A and as B against all other models\n",
    "    row_beats_col_freq = (\n",
    "        (a_win + b_win.T) /\n",
    "        (num_battles + num_battles.T)\n",
    "    )\n",
    "\n",
    "    # Arrange by proportion of wins\n",
    "    prop_wins = row_beats_col_freq.mean(axis=1).sort_values(ascending=False)\n",
    "    model_names = list(prop_wins.keys())\n",
    "    row_beats_col = row_beats_col_freq.loc[model_names, model_names]\n",
    "    return row_beats_col\n",
    "\n",
    "\n",
    "# Delete all records outside of the 40 selected models\n",
    "df = df[(df['model_a'].isin(models_of_interest)) & (df['model_b'].isin(models_of_interest))]\n",
    "\n",
    "row_beats_col_freq = compute_head_to_head_win_rate(df)\n",
    "fig = px.bar(\n",
    "    row_beats_col_freq.mean(axis=1).sort_values(ascending=False),\n",
    "    title=\"Approximate Win Rate Against Other Models\",\n",
    "    text_auto=\".2f\"\n",
    ")\n",
    "fig.update_layout(yaxis_title=\"Average Win Rate\", xaxis_title=\"Model\", showlegend=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we could assume that models that tend to be more aligned with human preferences are larger or newer.\n",
    "We'll also note that the GPT-4 models are more performant than the other models from this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run the human votes through an [Elo rating system](https://en.wikipedia.org/wiki/Elo_rating_system)\n",
    "\n",
    "We'll pass along all these head-to-head battles into an Elo rating system, commonly used in the world of chess to determine a skill rating relative to other players. In general, the dataset indicates the winner from a pair of models, and the winner gains some Elo, while the loser's Elo is lowered. You can read more about the details of Elo rating systems [here](https://en.wikipedia.org/wiki/Elo_rating_system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Elo rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>starling-lm-7b-alpha</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openchat-3.5</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pplx-7b-online</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>qwen-14b-chat</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Elo rating\n",
       "1           gpt-4-0125-preview        1173\n",
       "2           gpt-4-1106-preview        1155\n",
       "3                   gpt-4-0314        1139\n",
       "4                   gpt-4-0613        1089\n",
       "5                   gemini-pro        1078\n",
       "6           gpt-3.5-turbo-0613        1077\n",
       "7               mistral-medium        1075\n",
       "8                     claude-1        1066\n",
       "9                   claude-2.0        1060\n",
       "10  mixtral-8x7b-instruct-v0.1        1055\n",
       "11                 yi-34b-chat        1047\n",
       "12                  claude-2.1        1045\n",
       "13          gemini-pro-dev-api        1043\n",
       "14          gpt-3.5-turbo-0314        1041\n",
       "15                wizardlm-70b        1039\n",
       "16              tulu-2-dpo-70b        1037\n",
       "17            llama-2-70b-chat        1033\n",
       "18        starling-lm-7b-alpha        1032\n",
       "19             llama-2-7b-chat        1025\n",
       "20            claude-instant-1        1017\n",
       "21                  vicuna-33b        1015\n",
       "22             pplx-70b-online        1015\n",
       "23                openchat-3.5        1009\n",
       "24                wizardlm-13b         998\n",
       "25      codellama-34b-instruct         983\n",
       "26            llama-2-13b-chat         982\n",
       "27          gpt-3.5-turbo-1106         974\n",
       "28              pplx-7b-online         965\n",
       "29                  vicuna-13b         964\n",
       "30              zephyr-7b-beta         963\n",
       "31               qwen-14b-chat         944\n",
       "32                      palm-2         943\n",
       "33                   koala-13b         933\n",
       "34         mistral-7b-instruct         929\n",
       "35                   vicuna-7b         915\n",
       "36                  alpaca-13b         860\n",
       "37            RWKV-4-Raven-14B         853\n",
       "38              fastchat-t5-3b         813\n",
       "39            oasst-pythia-12b         810\n",
       "40                  chatglm-6b         808"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_elo(battles, K=4, SCALE=400, BASE=10, INIT_RATING=1000):\n",
    "    rating = defaultdict(lambda: INIT_RATING)\n",
    "\n",
    "    for rd, model_a, model_b, winner_model_a, winner_model_b, winner_tie in battles[['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie']].itertuples():\n",
    "        ra = rating[model_a]\n",
    "        rb = rating[model_b]\n",
    "        ea = 1 / (1 + BASE ** ((rb - ra) / SCALE))\n",
    "        eb = 1 / (1 + BASE ** ((ra - rb) / SCALE))\n",
    "        \n",
    "        # Determine the winner based on the one-hot encoded winner columns\n",
    "        if winner_model_a == 1:\n",
    "            sa = 1\n",
    "        elif winner_model_b == 1:\n",
    "            sa = 0\n",
    "        elif winner_tie == 1:\n",
    "            sa = 0.5\n",
    "        else:\n",
    "            raise Exception(\"no winner selected\")\n",
    "\n",
    "        # Update the ratings\n",
    "        rating[model_a] += K * (sa - ea)\n",
    "        rating[model_b] += K * (1 - sa - eb)\n",
    "\n",
    "    return rating\n",
    "\n",
    "def display_leaderboard(ratings):\n",
    "    df = pd.DataFrame([\n",
    "        [n, ratings[n]] for n in ratings.keys()\n",
    "    ], columns=[\"Model\", \"Elo rating\"]).sort_values(\"Elo rating\", ascending=False).reset_index(drop=True)\n",
    "    df[\"Elo rating\"] = (df[\"Elo rating\"] + 0.5).astype(int)\n",
    "    df.index = df.index + 1\n",
    "    return df\n",
    "\n",
    "elo_ratings = compute_elo(df)\n",
    "display_leaderboard(elo_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bootstrap the results to make sure the Elo scores are stable and reliable. As a result, we can display confidence intervals later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bootstrap: 100%|| 100/100 [00:06<00:00, 15.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Elo rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>starling-lm-7b-alpha</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>openchat-3.5</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pplx-7b-online</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>qwen-14b-chat</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Elo rating\n",
       "0           gpt-4-1106-preview        1186\n",
       "1           gpt-4-0125-preview        1176\n",
       "2                   gpt-4-0314        1117\n",
       "3                   gpt-4-0613        1091\n",
       "4               mistral-medium        1082\n",
       "5                     claude-1        1073\n",
       "6                   claude-2.0        1061\n",
       "7                   gemini-pro        1053\n",
       "8           gpt-3.5-turbo-0314        1052\n",
       "9   mixtral-8x7b-instruct-v0.1        1048\n",
       "10          gemini-pro-dev-api        1047\n",
       "11          gpt-3.5-turbo-0613        1044\n",
       "12                  claude-2.1        1044\n",
       "13                 yi-34b-chat        1043\n",
       "14        starling-lm-7b-alpha        1038\n",
       "15            llama-2-70b-chat        1037\n",
       "16            claude-instant-1        1037\n",
       "17                wizardlm-70b        1037\n",
       "18                  vicuna-33b        1031\n",
       "19              tulu-2-dpo-70b        1017\n",
       "20             pplx-70b-online        1011\n",
       "21                openchat-3.5        1010\n",
       "22                wizardlm-13b        1004\n",
       "23          gpt-3.5-turbo-1106         995\n",
       "24            llama-2-13b-chat         988\n",
       "25             llama-2-7b-chat         984\n",
       "26      codellama-34b-instruct         980\n",
       "27              zephyr-7b-beta         979\n",
       "28                  vicuna-13b         967\n",
       "29              pplx-7b-online         965\n",
       "30                      palm-2         945\n",
       "31               qwen-14b-chat         943\n",
       "32         mistral-7b-instruct         934\n",
       "33                   vicuna-7b         931\n",
       "34                   koala-13b         912\n",
       "35            RWKV-4-Raven-14B         851\n",
       "36                  alpaca-13b         845\n",
       "37            oasst-pythia-12b         824\n",
       "38                  chatglm-6b         813\n",
       "39              fastchat-t5-3b         808"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_bootstrap_result(battles, func_compute_elo, num_round):\n",
    "    rows = []\n",
    "    for i in tqdm(range(num_round), desc=\"bootstrap\"):\n",
    "        rows.append(func_compute_elo(battles.sample(frac=1.0, replace=True)))\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df[df.median().sort_values(ascending=False).index]\n",
    "\n",
    "BOOTSTRAP_ROUNDS = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "bootstrap_elo_lu = compute_bootstrap_result(df, compute_elo, BOOTSTRAP_ROUNDS)\n",
    "bootstrap_lu_median = bootstrap_elo_lu.median().reset_index().set_axis([\"model\", \"Elo rating\"], axis=1)\n",
    "bootstrap_lu_median[\"Elo rating\"] = (bootstrap_lu_median[\"Elo rating\"] + 0.5).astype(int)\n",
    "bootstrap_lu_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Verify that the Elo leaderboard agrees with our hypothesis\n",
    "\n",
    "From the leaderboard above, we immediately see that the GPT-4 models are the top performers. We may also notice that the larger and newer LLMs tend to appear higher up on the leaderboard. By inspection, the order of models by win rate and by Elo score are very similar, verifying that the Elo rating system works!\n",
    "\n",
    "Let's go ahead and add on the confidence intervals in a more appealing plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           28.377656090672417,
           25.94465213481135,
           23.25899122755436,
           35.478498325451255,
           24.4078338848592,
           26.987370925577352,
           25.130136578448855,
           30.37904890822665,
           26.195664988856834,
           25.225478455595976,
           36.24811296699636,
           34.77664279196824,
           30.92123910983605,
           26.34624996209027,
           35.54821569224032,
           27.26250394761496,
           27.84548395449542,
           28.814607141242277,
           24.331196651703067,
           28.658550155876355
          ],
          "arrayminus": [
           24.864739585647385,
           27.173657858102388,
           32.467500363537056,
           26.351356512143866,
           26.260582788634565,
           28.788448077824796,
           28.710716355064733,
           26.1109503701432,
           27.219672785016655,
           31.954038331743845,
           32.75390292914619,
           29.887007361981432,
           37.25408189477878,
           28.48024471120584,
           25.874577764137484,
           27.40379146959515,
           30.287988744451127,
           27.078016057473974,
           25.400292937562995,
           26.512737504539132
          ],
          "type": "data"
         },
         "mode": "markers+text",
         "text": [
          1186.48,
          1176.33,
          1116.53,
          1091.34,
          1081.54,
          1072.69,
          1061.07,
          1053.17,
          1052.09,
          1048.17,
          1047.19,
          1044.33,
          1043.73,
          1042.62,
          1038.47,
          1037.48,
          1037.4,
          1036.89,
          1030.76,
          1017.5
         ],
         "textfont": {
          "size": 8
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "gpt-4-1106-preview",
          "gpt-4-0125-preview",
          "gpt-4-0314",
          "gpt-4-0613",
          "mistral-medium",
          "claude-1",
          "claude-2.0",
          "gemini-pro",
          "gpt-3.5-turbo-0314",
          "mixtral-8x7b-instruct-v0.1",
          "gemini-pro-dev-api",
          "gpt-3.5-turbo-0613",
          "claude-2.1",
          "yi-34b-chat",
          "starling-lm-7b-alpha",
          "llama-2-70b-chat",
          "claude-instant-1",
          "wizardlm-70b",
          "vicuna-33b",
          "tulu-2-dpo-70b"
         ],
         "xaxis": "x",
         "y": [
          1186.4830292456656,
          1176.3314894272085,
          1116.531754780052,
          1091.337381651886,
          1081.5424946399294,
          1072.6906283449275,
          1061.0704904486556,
          1053.1686620369258,
          1052.091650088677,
          1048.1673600591198,
          1047.188926858266,
          1044.3284719825576,
          1043.7328690478964,
          1042.6223347948487,
          1038.4696919747728,
          1037.4760246305748,
          1037.4013530118643,
          1036.8872027455377,
          1030.7619806606554,
          1017.4979104625443
         ],
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": [
           28.62793805621436,
           25.615587732546146,
           27.09126410308886,
           32.25338126295219,
           26.017995347051283,
           32.21551616294653,
           27.794065755080737,
           20.943977179516992,
           25.579252099286123,
           30.99199099310681,
           22.261794249251693,
           26.60617240265458,
           33.41397613570575,
           24.711739769608585,
           27.21425501040642,
           28.23268854620801,
           29.94301394122442,
           26.875521132019117,
           30.749265466372663,
           25.40207739481764
          ],
          "arrayminus": [
           25.851370564159083,
           36.230476139561006,
           26.97445352212128,
           30.259570598783853,
           28.679255046470416,
           25.126583781885074,
           24.7520120221169,
           27.862409123975,
           25.74738642525449,
           28.80956677983545,
           35.63077395015796,
           27.71407406431922,
           34.576009586350324,
           30.94399809049696,
           27.566115888079707,
           23.65071683945564,
           31.287553855513124,
           26.360723859170776,
           31.50798965764784,
           27.574265408011115
          ],
          "type": "data"
         },
         "mode": "markers+text",
         "text": [
          1010.92,
          1009.78,
          1004.05,
          994.79,
          987.9,
          983.71,
          979.97,
          979.39,
          966.73,
          965.26,
          945.26,
          943,
          934.23,
          930.73,
          912.13,
          850.68,
          845.24,
          824.26,
          812.84,
          807.99
         ],
         "textfont": {
          "size": 8
         },
         "textposition": "top center",
         "type": "scatter",
         "x": [
          "pplx-70b-online",
          "openchat-3.5",
          "wizardlm-13b",
          "gpt-3.5-turbo-1106",
          "llama-2-13b-chat",
          "llama-2-7b-chat",
          "codellama-34b-instruct",
          "zephyr-7b-beta",
          "vicuna-13b",
          "pplx-7b-online",
          "palm-2",
          "qwen-14b-chat",
          "mistral-7b-instruct",
          "vicuna-7b",
          "koala-13b",
          "RWKV-4-Raven-14B",
          "alpaca-13b",
          "oasst-pythia-12b",
          "chatglm-6b",
          "fastchat-t5-3b"
         ],
         "xaxis": "x2",
         "y": [
          1010.921717592237,
          1009.7790275268876,
          1004.0493560414175,
          994.7948517295631,
          987.8963893765481,
          983.713664796194,
          979.9697480542216,
          979.3888552879381,
          966.7331885607432,
          965.2619973921345,
          945.2621945777282,
          942.9986966285219,
          934.2308602999462,
          930.7267383398504,
          912.13121149126,
          850.6845766841877,
          845.2353608304705,
          824.2616122534962,
          812.8350008609581,
          807.9896272750839
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Top Performers",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.9999999999999999,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Rest of Performers",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.35,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Model"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Model"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.6499999999999999,
          0.9999999999999999
         ],
         "range": [
          967.4979104625443,
          1236.4830292456656
         ],
         "title": {
          "text": "Rating"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.35
         ],
         "range": [
          757.9896272750839,
          1060.921717592237
         ],
         "title": {
          "text": "Rating"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_bootstrap_scores(df):\n",
    "    bars = df.quantile([.025, .5, .975]).T.reset_index(names='model')\n",
    "    bars.columns = ['model', 'lower', 'rating', 'upper']\n",
    "    bars = bars.sort_values('rating', ascending=False)\n",
    "\n",
    "    bars['error_y'] = bars['upper'] - bars['rating']\n",
    "    bars['error_y_minus'] = bars['rating'] - bars['lower']\n",
    "    bars['rating_rounded'] = bars['rating'].round(2)\n",
    "\n",
    "    mid_index = len(bars) // 2\n",
    "    top_half, bottom_half = bars.iloc[:mid_index], bars.iloc[mid_index:]\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Top Performers\", \"Rest of Performers\"), vertical_spacing=0.3)\n",
    "\n",
    "    # Function to add traces\n",
    "    def add_trace(data, row):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data['model'], \n",
    "                y=data['rating'], \n",
    "                error_y=dict(type='data', array=data['error_y'], arrayminus=data['error_y_minus']),\n",
    "                mode='markers+text',\n",
    "                text=data['rating_rounded'],\n",
    "                textposition='top center',\n",
    "                textfont=dict(size=8)\n",
    "            ),\n",
    "            row=row, col=1\n",
    "        )\n",
    "        \n",
    "    # Add top half and bottom half plots\n",
    "    add_trace(top_half, row=1)\n",
    "    add_trace(bottom_half, row=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        height=800\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Model\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Rating\", row=1, col=1, range=[top_half['rating'].min() - 50, top_half['rating'].max() + 50])\n",
    "    fig.update_xaxes(title_text=\"Model\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Rating\", row=2, col=1, range=[bottom_half['rating'].min() - 50, bottom_half['rating'].max() + 50])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = visualize_bootstrap_scores(bootstrap_elo_lu)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Learn that the automated judges in AutoArena produced a very similar leaderboard\n",
    "\n",
    "By now, your leaderboard on [AutoArena](http://localhost:8899) should have a good number of votes on most of the models you've uploaded. Let's click on `Recompute Leaderboard` to refresh the leaderboard's content.\n",
    "\n",
    "<img src=\"./assets/recompute.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "You'll find that the leaderboard within [AutoArena](http://localhost:8899) is very similar to the placement of models shown above with slight shifts. Again, we'll notice that the newer GPT-4 models are at the top of the leaderboard, and the larger/newer models tend to dominate among the top 20 performers. Consequently, the bottom 20 performers generally consist of the smaller/older models. None of this should be surprising, but it demonstrates that the jury of automated judges (`gpt-4o-mini` in this case) is able to leverage an Elo rating system to create an accurate leaderboard of many LLMs efficiently.\n",
    "\n",
    "\n",
    "Here is an example of what you might see in [AutoArena](http://localhost:8899).\n",
    "\n",
    "\n",
    "<img src=\"./assets/leaderboard.png\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook, we evaluated language model responses using **[AutoArena by Kolena](https://github.com/kolenaIO/autoarena)**, the platform designed to rank LLM generations through head-to-head comparisons judged by an automated jury of other LLMs.\n",
    "\n",
    "\n",
    "We used a dataset that included human preferences in pairwise model comparisons and uploaded its data without the human indicators into AutoArena. Then, we set up a jury of automated judges to critique the raw model responses given their respective prompts. To ensure this strategy is sound, we hypothesized which types of LLMs would align most closely with human voters' preferences from observing overall winning rates. By using an Elo rating system, we ranked models using the human preferences from the dataset and compared it to the generated leaderboard in Autoarena. We compared the Elo leaderboard with our hypothesis and *ground truth* leaderboard to find that the automated judges produced a strikingly similar ranking, validating our approach.\n",
    "\n",
    "AutoArena can effectively automate model benchmarking and align results with human preferences, or any other policies through creating appropriate system prompts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
